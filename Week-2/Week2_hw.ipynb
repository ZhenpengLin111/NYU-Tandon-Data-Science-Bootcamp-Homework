{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "760f4785-293e-4127-9c53-6876089371b7",
      "metadata": {},
      "source": [
        "# Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "293e1173-c5b9-487b-b9c3-6322ee1ac896",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ea33815d-c3cd-47b0-bd11-ce3a1c90d2e6",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vertical stacking of A and B: \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "Horizontal stacking of A and B: \n",
            "[1 2 3 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "# 1. Define two custom numpy arrays, say A and B. Generate two new numpy arrays by stacking A and B vertically and horizontally\n",
        "A = np.array([1,2,3])\n",
        "B = np.array([4,5,6])\n",
        "\n",
        "# Vertical stacking\n",
        "vert_stack = np.vstack((A,B))\n",
        "print(\"Vertical stacking of A and B: \")\n",
        "print(vert_stack)\n",
        "\n",
        "# Horizontal stacking\n",
        "hori_stack = np.hstack((A,B))\n",
        "print(\"Horizontal stacking of A and B: \")\n",
        "print(hori_stack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5b172f11-4de2-4553-800f-c2029389e20d",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Common elements between A and B:  [3 4 5]\n"
          ]
        }
      ],
      "source": [
        "# 2. Find common elements between A and B. [Hint: Intersection of two sets]\n",
        "A = np.array([1,2,3,4,5])\n",
        "B = np.array([3,4,5,6,7])\n",
        "common = np.intersect1d(A,B)\n",
        "print(\"Common elements between A and B: \", common)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a6feeba-cc41-45e4-970e-9aaf30c1036f",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A:  [ 2  5  7 10 12  9  4]\n",
            "All numbers from A that are between 5 and 10:  [ 5  7 10  9]\n"
          ]
        }
      ],
      "source": [
        "# 3. Extract all numbers from A which are within a specific range. eg between 5 and 10. [Hint: np.where() might be useful or boolean masks]\n",
        "A = np.array([2, 5, 7, 10, 12, 9, 4])\n",
        "print(\"A: \", A)\n",
        "\n",
        "'''\n",
        "(A >= 5) → [False, True, True, True, True, True, False]\n",
        "(A <= 10) → [ True, True, True, True, False, True, True]\n",
        "Combine both with & → only elements between 5 and 10 (inclusive) remain.\n",
        "'''\n",
        "result = A[(A >= 5) & (A <= 10)]\n",
        "print(\"All numbers from A that are between 5 and 10: \", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "88369dc6-01a0-421b-9f4d-a9c4574721b9",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rows of iris_2d that has petallength (3rd column) > 1.5: \n",
            "[[5.4 3.9 1.7 0.4]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n"
          ]
        }
      ],
      "source": [
        "# 4. Filter the rows of iris_2d that has petallength (3rd column) > 1.5 and sepallength (1st column) < 5.0\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])\n",
        "# print(iris_2d)\n",
        "\n",
        "#  Filter the rows of iris_2d that has petallength (3rd column) > 1.5\n",
        "filtered1 = iris_2d[iris_2d[:,2] > 1.5]\n",
        "print(\"The rows of iris_2d that has petallength (3rd column) > 1.5: \")\n",
        "print(filtered1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1f79c375-88f6-4182-9d46-a098b8a6e50a",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rows of iris_2d that has sepallength (1st column) < 5.0: \n",
            "[[4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [4.9 2.5 4.5 1.7]]\n"
          ]
        }
      ],
      "source": [
        "# Filter the rows of iris_2d that has sepallength (1st column) < 5.0\n",
        "filtered2 = iris_2d[iris_2d[:,0] < 5.0]\n",
        "print(\"The rows of iris_2d that has sepallength (1st column) < 5.0: \")\n",
        "print(filtered2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f50ce9d",
      "metadata": {},
      "source": [
        "# Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "608d407b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8d7827c0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0) from the dataframe:\n",
            "   Manufacturer    Model     Type\n",
            "0         Acura  Integra    Small\n",
            "20     Chrysler  LeBaron  Compact\n",
            "40        Honda  Prelude   Sporty\n",
            "60      Mercury   Cougar  Midsize\n",
            "80       Subaru   Loyale    Small\n"
          ]
        }
      ],
      "source": [
        "# 1. From df filter the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0).\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "\n",
        "subset = [\"Manufacturer\", \"Model\", \"Type\"]\n",
        "sample = df.loc[df.index % 20 == 0, subset]\n",
        "\n",
        "print(\"Filtered the 'Manufacturer', 'Model' and 'Type' for every 20th row starting from 1st (row 0) from the dataframe:\")\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9fb6c1ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe after replacing missing values in Min.Price and Max.Price columns with their respective mean:\n",
            "   Manufacturer    Model     Type  Min.Price  Price  Max.Price  MPG.city  \\\n",
            "0         Acura  Integra    Small  12.900000   15.9  18.800000      25.0   \n",
            "1           NaN   Legend  Midsize  29.200000   33.9  38.700000      18.0   \n",
            "2          Audi       90  Compact  25.900000   29.1  32.300000      20.0   \n",
            "3          Audi      100  Midsize  17.118605   37.7  44.600000      19.0   \n",
            "4           BMW     535i  Midsize  17.118605   30.0  21.459091      22.0   \n",
            "..          ...      ...      ...        ...    ...        ...       ...   \n",
            "88   Volkswagen  Eurovan      Van  16.600000   19.7  22.700000      17.0   \n",
            "89   Volkswagen   Passat  Compact  17.600000   20.0  22.400000      21.0   \n",
            "90   Volkswagen  Corrado   Sporty  22.900000   23.3  23.700000      18.0   \n",
            "91        Volvo      240  Compact  21.800000   22.7  23.500000      21.0   \n",
            "92          NaN      850  Midsize  24.800000   26.7  28.500000      20.0   \n",
            "\n",
            "    MPG.highway             AirBags DriveTrain  ... Passengers  Length  \\\n",
            "0          31.0                 NaN      Front  ...        5.0   177.0   \n",
            "1          25.0  Driver & Passenger      Front  ...        5.0   195.0   \n",
            "2          26.0         Driver only      Front  ...        5.0   180.0   \n",
            "3          26.0  Driver & Passenger        NaN  ...        6.0   193.0   \n",
            "4          30.0                 NaN       Rear  ...        4.0   186.0   \n",
            "..          ...                 ...        ...  ...        ...     ...   \n",
            "88         21.0                 NaN      Front  ...        7.0   187.0   \n",
            "89         30.0                 NaN      Front  ...        5.0   180.0   \n",
            "90         25.0                 NaN      Front  ...        4.0   159.0   \n",
            "91         28.0         Driver only       Rear  ...        5.0   190.0   \n",
            "92         28.0  Driver & Passenger      Front  ...        5.0   184.0   \n",
            "\n",
            "    Wheelbase  Width  Turn.circle Rear.seat.room  Luggage.room  Weight  \\\n",
            "0       102.0   68.0         37.0           26.5           NaN  2705.0   \n",
            "1       115.0   71.0         38.0           30.0          15.0  3560.0   \n",
            "2       102.0   67.0         37.0           28.0          14.0  3375.0   \n",
            "3       106.0    NaN         37.0           31.0          17.0  3405.0   \n",
            "4       109.0   69.0         39.0           27.0          13.0  3640.0   \n",
            "..        ...    ...          ...            ...           ...     ...   \n",
            "88      115.0   72.0         38.0           34.0           NaN  3960.0   \n",
            "89      103.0   67.0         35.0           31.5          14.0  2985.0   \n",
            "90       97.0   66.0         36.0           26.0          15.0  2810.0   \n",
            "91      104.0   67.0         37.0           29.5          14.0  2985.0   \n",
            "92      105.0   69.0         38.0           30.0          15.0  3245.0   \n",
            "\n",
            "     Origin                Make  \n",
            "0   non-USA       Acura Integra  \n",
            "1   non-USA        Acura Legend  \n",
            "2   non-USA             Audi 90  \n",
            "3   non-USA            Audi 100  \n",
            "4   non-USA            BMW 535i  \n",
            "..      ...                 ...  \n",
            "88      NaN  Volkswagen Eurovan  \n",
            "89  non-USA   Volkswagen Passat  \n",
            "90  non-USA  Volkswagen Corrado  \n",
            "91  non-USA           Volvo 240  \n",
            "92  non-USA           Volvo 850  \n",
            "\n",
            "[93 rows x 27 columns]\n"
          ]
        }
      ],
      "source": [
        "# 2. Replace missing values in Min.Price and Max.Price columns with their respective mean.\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
        "# Get the mean of Min.Price and Max.Price columns\n",
        "min_price_mean = df[\"Min.Price\"].mean()\n",
        "max_price_mean = df[\"Max.Price\"].mean()\n",
        "\n",
        "# Fill NaN values in Min.Price and Max.Price columns with their respective mean using fillna function\n",
        "df[\"Max.Price\"] = df[\"Max.Price\"].fillna(max_price_mean)\n",
        "df[\"Min.Price\"] = df[\"Min.Price\"].fillna(min_price_mean)\n",
        "\n",
        "print(\"Dataframe after replacing missing values in Min.Price and Max.Price columns with their respective mean:\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "96f61e68",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rows of the dataframe with row sum > 100 are the following: \n",
            "     0   1   2   3\n",
            "1   17  21  30  38\n",
            "2   27  23  15  37\n",
            "4   28  20  26  32\n",
            "5   20  22  39  36\n",
            "6   31  23  37  25\n",
            "9   18  16  35  32\n",
            "13  27  20  35  26\n",
            "14  35  26  22  25\n"
          ]
        }
      ],
      "source": [
        "# 3. How to get the rows of a dataframe with row sum > 100?\n",
        "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
        "filtered = df[df.sum(axis=1) > 100]\n",
        "print(\"The rows of the dataframe with row sum > 100 are the following: \")\n",
        "print(filtered)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
